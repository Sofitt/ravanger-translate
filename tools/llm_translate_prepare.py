#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ñ–∞–π–ª–æ–≤ –ø–µ—Ä–µ–≤–æ–¥–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —á–µ—Ä–µ–∑ LLM
–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç .rpy —Ñ–∞–π–ª—ã –≤ JSON —Ñ–æ—Ä–º–∞—Ç
"""

import os
import re
import json
import argparse
from typing import List, Dict, Tuple


class TranslationPreparer:
    def __init__(self):
        self.strings = []
    
    def parse_rpy_file(self, file_path: str) -> List[Dict]:
        """–ü–∞—Ä—Å–∏—Ç .rpy —Ñ–∞–π–ª –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞"""
        
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
        
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ –±–ª–æ–∫–æ–≤ –ø–µ—Ä–µ–≤–æ–¥–∞
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º (?:[^"\\]|\\.)* –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–∞–≤—ã—á–µ–∫
        pattern = r'    # ([^\n]+)\n    old "((?:[^"\\\\]|\\\\.)*)"\n    new "((?:[^"\\\\]|\\\\.)*)"'
        matches = re.findall(pattern, content, re.MULTILINE | re.DOTALL)
        
        strings = []
        for idx, (comment, old_text, new_text) in enumerate(matches):
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç
            analysis = self._analyze_text(old_text)
            
            strings.append({
                "id": idx,
                "comment": comment.strip(),
                "original": old_text,
                "translation": new_text,
                "context": self._detect_context(old_text, comment),
                "tags": analysis["tags"],
                "variables_curly": analysis["variables_curly"],
                "variables_square": analysis["variables_square"],
                "special_chars": analysis["special_chars"]
            })
        
        return strings
    
    def _analyze_text(self, text: str) -> Dict:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–≥–∏, –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ, —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã"""
        
        # –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –≤ —Ñ–∏–≥—É—Ä–Ω—ã—Ö —Å–∫–æ–±–∫–∞—Ö
        variables_curly = re.findall(r'\{(\w+)\}', text)
        
        # –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –≤ –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã—Ö —Å–∫–æ–±–∫–∞—Ö
        variables_square = re.findall(r'\[(\w+)\]', text)
        
        # –¢–µ–≥–∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        tags = re.findall(r'\{/?(?:color|b|i|u|size|center)[^}]*\}', text)
        
        # –°–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã
        special_chars = {
            "newlines": text.count('\\n'),
            "tabs": text.count('\\t'),
            "escaped_quotes": text.count('\\"')
        }
        
        return {
            "variables_curly": variables_curly,
            "variables_square": variables_square,
            "tags": tags,
            "special_chars": special_chars
        }
    
    def _detect_context(self, text: str, comment: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å—Ç—Ä–æ–∫–∏ (–¥–∏–∞–ª–æ–≥, –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å, –∏ —Ç.–¥.)"""
        
        # –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ –æ–±—ã—á–Ω–æ –∫–æ—Ä–æ—Ç–∫–∏–µ
        if len(text) < 20 and not any(c in text for c in '.!?'):
            return "ui"
        
        # –ù–∞–∑–≤–∞–Ω–∏—è —Ñ–∞–π–ª–æ–≤ screen.rpy, options.rpy, gallery.rpy
        if any(name in comment.lower() for name in ['screen', 'option', 'gallery']):
            return "ui"
        
        # –î–∏–∞–ª–æ–≥–∏ –æ–±—ã—á–Ω–æ —Å–æ–¥–µ—Ä–∂–∞—Ç –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
        if any(c in text for c in '.!?'):
            return "dialogue"
        
        # –û—Å—Ç–∞–ª—å–Ω–æ–µ - –æ–±—â–∏–π —Ç–µ–∫—Å—Ç
        return "text"
    
    def prepare_module(self, module_file: str, output_file: str):
        """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –º–æ–¥—É–ª—å –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞"""
        
        print(f"üìÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –º–æ–¥—É–ª—å: {module_file}")
        
        strings = self.parse_rpy_file(module_file)
        
        # –ü–æ–¥—Å—á–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        total = len(strings)
        translated = sum(1 for s in strings if s["translation"].strip())
        empty = total - translated
        
        metadata = {
            "module": os.path.basename(module_file),
            "module_path": module_file,
            "total_strings": total,
            "translated": translated,
            "untranslated": empty,
            "source_language": "en",
            "target_language": "ru"
        }
        
        output = {
            "metadata": metadata,
            "strings": strings
        }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º JSON
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(output, f, ensure_ascii=False, indent=2)
        
        print(f"‚úÖ –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ: {total} —Å—Ç—Ä–æ–∫ ({translated} –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–æ, {empty} –ø—É—Å—Ç–æ)")
        print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤: {output_file}")
        
        return output
    
    def prepare_batch(self, modules_dir: str, output_dir: str, pattern: str = "*_ru.rpy"):
        """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –ø–∞–∫–µ—Ç –º–æ–¥—É–ª–µ–π"""
        
        import glob
        
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
        
        module_files = glob.glob(os.path.join(modules_dir, pattern))
        
        print(f"üîç –ù–∞–π–¥–µ–Ω–æ –º–æ–¥—É–ª–µ–π: {len(module_files)}")
        
        for module_file in module_files:
            basename = os.path.basename(module_file).replace('.rpy', '.json')
            output_file = os.path.join(output_dir, basename)
            
            try:
                self.prepare_module(module_file, output_file)
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {module_file}: {e}")
        
        print(f"\nüéâ –ì–æ—Ç–æ–≤–æ! –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –º–æ–¥—É–ª–µ–π: {len(module_files)}")


def main():
    parser = argparse.ArgumentParser(description="–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–æ–≤ –¥–ª—è LLM")
    parser.add_argument("--module", help="–ü—É—Ç—å –∫ –º–æ–¥—É–ª—é –ø–µ—Ä–µ–≤–æ–¥–∞ (.rpy)")
    parser.add_argument("--output", help="–ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É JSON —Ñ–∞–π–ª—É")
    parser.add_argument("--batch", help="–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤—Å–µ –º–æ–¥—É–ª–∏ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏")
    parser.add_argument("--batch-output", default="../temp_files/llm_json", 
                       help="–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –≤—ã—Ö–æ–¥–Ω—ã—Ö JSON (–ø—Ä–∏ --batch)")
    parser.add_argument("--pattern", default="*_ru.rpy",
                       help="–ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ñ–∞–π–ª–æ–≤ (–ø—Ä–∏ --batch)")
    
    args = parser.parse_args()
    
    preparer = TranslationPreparer()
    
    if args.batch:
        preparer.prepare_batch(args.batch, args.batch_output, args.pattern)
    elif args.module and args.output:
        preparer.prepare_module(args.module, args.output)
    else:
        # –†–µ–∂–∏–º –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –≤—Å–µ –º–æ–¥—É–ª–∏
        modules_dir = "../translation_modules"
        output_dir = "../temp_files/llm_json"
        
        print("üöÄ –†–µ–∂–∏–º –ø–∞–∫–µ—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        print(f"üìÅ –í—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {modules_dir}")
        print(f"üìÅ –í—ã—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {output_dir}")
        print()
        
        preparer.prepare_batch(modules_dir, output_dir)


if __name__ == "__main__":
    main()
