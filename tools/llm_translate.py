#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
–ü–µ—Ä–µ–≤–æ–¥ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ –ª–æ–∫–∞–ª—å–Ω—É—é LLM
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ backends: OpenAI-compatible API, llama.cpp, Ollama
"""

import os
import re
import json
import argparse
import time
from typing import List, Dict, Optional
from dataclasses import dataclass


@dataclass
class TranslationConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞"""
    backend: str = "openai"  # openai, ollama, llamacpp
    api_url: str = "http://localhost:8080/v1/chat/completions"
    api_key: str = "not-needed"
    model: str = "local-model"
    temperature: float = 0.1
    top_p: float = 0.7
    max_tokens: int = 2000
    batch_size: int = 10


class TranslationValidator:
    """–í–∞–ª–∏–¥–∞—Ç–æ—Ä –ø–µ—Ä–µ–≤–æ–¥–æ–≤"""

    @staticmethod
    def validate(original: str, translation: str) -> List[str]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –ø–µ—Ä–µ–≤–æ–¥–∞"""
        errors = []

        if not translation or not translation.strip():
            return errors  # –ü—É—Å—Ç—ã–µ –ø–µ—Ä–µ–≤–æ–¥—ã –Ω–µ –æ—à–∏–±–∫–∞

        # 1. –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –≤ —Ñ–∏–≥—É—Ä–Ω—ã—Ö —Å–∫–æ–±–∫–∞—Ö (–≤–∫–ª—é—á–∞—è {variable} –∏ {#variable})
        orig_vars_curly = set(re.findall(r'\{#?(\w+)\}', original))
        trans_vars_curly = set(re.findall(r'\{#?(\w+)\}', translation))
        if orig_vars_curly != trans_vars_curly:
            errors.append(f"–ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ {{}}: {orig_vars_curly} != {trans_vars_curly}")

        # 2. –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ —Å —Ä–µ—à–µ—Ç–∫–æ–π {#variable} - –¥–æ–ª–∂–Ω—ã —Å–æ—Ö—Ä–∞–Ω—è—Ç—å—Å—è –ø–æ–ª–Ω–æ—Å—Ç—å—é
        orig_hash_vars = re.findall(r'\{#\w+\}', original)
        trans_hash_vars = re.findall(r'\{#\w+\}', translation)
        if orig_hash_vars != trans_hash_vars:
            errors.append(f"–ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ {{#}}: {orig_hash_vars} != {trans_hash_vars}")

        # 3. –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –≤ –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã—Ö —Å–∫–æ–±–∫–∞—Ö (–≤–∫–ª—é—á–∞—è –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã !tc, !t, !u –∏ —Ç.–¥.)
        orig_vars_square = re.findall(r'\[[^\]]+\]', original)
        trans_vars_square = re.findall(r'\[[^\]]+\]', translation)
        if orig_vars_square != trans_vars_square:
            errors.append(f"–ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ []: {orig_vars_square} != {trans_vars_square}")

        # 4. –¢–µ–≥–∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        orig_tags = re.findall(r'\{/?(?:color|b|i|u|size|center)[^}]*\}', original)
        trans_tags = re.findall(r'\{/?(?:color|b|i|u|size|center)[^}]*\}', translation)
        if orig_tags != trans_tags:
            errors.append(f"–¢–µ–≥–∏: {orig_tags} != {trans_tags}")

        # 5. –ü–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫ (escape-–ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ \\n)
        if original.count('\\n') != translation.count('\\n'):
            errors.append(f"\\n: {original.count('\\n')} != {translation.count('\\n')}")

        # 6. –†–µ–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–≤–æ–¥—ã —Å—Ç—Ä–æ–∫ (—Å–∏–º–≤–æ–ª \n) - –Ω–µ –¥–æ–ª–∂–Ω—ã –¥–æ–±–∞–≤–ª—è—Ç—å—Å—è
        orig_real_newlines = original.count('\n')
        trans_real_newlines = translation.count('\n')
        if orig_real_newlines != trans_real_newlines:
            errors.append(f"–†–µ–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–≤–æ–¥—ã —Å—Ç—Ä–æ–∫: {orig_real_newlines} != {trans_real_newlines}")

        # 7. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–±–µ–ª–æ–≤ –ø–µ—Ä–µ–¥ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏ {#variable}
        # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã word{#variable} –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –ø—Ä–æ–±–µ–ª–∞
        orig_no_space = re.findall(r'\w\{#\w+\}', original)
        trans_with_space = re.findall(r'\w\s+\{#\w+\}', translation)
        if orig_no_space and trans_with_space:
            errors.append(f"–õ–∏—à–Ω–∏–π –ø—Ä–æ–±–µ–ª –ø–µ—Ä–µ–¥ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π: –Ω–∞–π–¥–µ–Ω–æ {len(trans_with_space)} —Å–ª—É—á–∞–µ–≤")

        # 8. –ù–µ—ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏
        if '"' in translation and '\\"' not in translation:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –Ω–µ –≤–Ω–µ—à–Ω–∏–µ –∫–∞–≤—ã—á–∫–∏
            inner_text = translation.strip('"')
            if '"' in inner_text:
                errors.append('–ö–∞–≤—ã—á–∫–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω—ã: \\"')

        return errors


class LLMTranslator:
    """–ü–µ—Ä–µ–≤–æ–¥—á–∏–∫ —á–µ—Ä–µ–∑ LLM"""

    def __init__(self, config: TranslationConfig):
        self.config = config
        self.validator = TranslationValidator()
        # system_prompt –∑–∞–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω - –ø—Ä–∞–≤–∏–ª–∞ –∑–∞—à–∏—Ç—ã –≤ –º–æ–¥–µ–ª—å
        # self.system_prompt = self._create_system_prompt()

    def _call_openai_api(self, messages: List[Dict]) -> Optional[str]:
        """–í—ã–∑–æ–≤ API (OpenAI –∏–ª–∏ Ollama)"""
        try:
            import requests

            if self.config.backend == "ollama":
                # –§–æ—Ä–º–∞—Ç –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è Ollama
                data = {
                    "model": self.config.model,
                    "messages": messages,
                    "options": {
                        "temperature": self.config.temperature,
                        "top_p": self.config.top_p,
                        "num_predict": self.config.max_tokens
                    },
                    "stream": False
                }

                # Ollama –Ω–µ —Ç—Ä–µ–±—É–µ—Ç API –∫–ª—é—á–∞
                headers = {"Content-Type": "application/json"}

                response = requests.post(
                    self.config.api_url,
                    headers=headers,
                    json=data,
                    timeout=300  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ç–∞–π–º–∞—É—Ç –¥–ª—è Ollama
                )

                response.raise_for_status()
                result = response.json()

                # –§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ Ollama
                return result["message"]["content"].strip()

            else:
                # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç OpenAI
                headers = {
                    "Content-Type": "application/json",
                    "Authorization": f"Bearer {self.config.api_key}"
                }

                data = {
                    "model": self.config.model,
                    "messages": messages,
                    "temperature": self.config.temperature,
                    "max_tokens": self.config.max_tokens
                }

                response = requests.post(
                    self.config.api_url,
                    headers=headers,
                    json=data,
                    timeout=120
                )

                response.raise_for_status()
                result = response.json()

                return result["choices"][0]["message"]["content"].strip()

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ API ({self.config.backend}): {e}")
            if hasattr(e, 'response') and hasattr(e.response, 'text'):
                print(f"–û—Ç–≤–µ—Ç —Å–µ—Ä–≤–µ—Ä–∞: {e.response.text}")
            return None

    def should_skip_translation(self, text: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥ —ç—Ç–æ–π —Å—Ç—Ä–æ–∫–∏"""
        # –°–ª—É–∂–µ–±–Ω—ã–µ —Å–ª–æ–≤–∞ Ren'Py
        renpy_keywords = {
            "centered", "left", "right", "top", "bottom",
            "True", "False", "None"
        }

        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ —Å–ª–æ–≤–∞
        if text.strip() in renpy_keywords:
            return True

        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏–µ —Å—Ç—Ä–æ–∫–∏ (1-2 —Å–∏–º–≤–æ–ª–∞)
        if len(text.strip()) <= 2:
            return True

        return False

    def translate_single(self, text: str, context: str = "", speaker_gender: str = "") -> Optional[str]:
        """–ü–µ—Ä–µ–≤–æ–¥–∏—Ç –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É"""

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥
        if self.should_skip_translation(text):
            return text  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π

        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ Instruct
        # –ü—Ä–∞–≤–∏–ª–∞ –ø–µ—Ä–µ–≤–æ–¥–∞ –∑–∞—à–∏—Ç—ã –≤ –º–æ–¥–µ–ª—å, –ø–æ—ç—Ç–æ–º—É –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç–æ–π —Ñ–æ—Ä–º–∞—Ç
        gender_prefix = f"{speaker_gender}: " if speaker_gender else ""
        user_prompt = f'[INST]–ü–µ—Ä–µ–≤–µ–¥–∏ {gender_prefix} {text} [/INST]'

        # –î–ª—è Ollama –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫–∞–∫ –æ–±—ã—á–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        messages = [
            {"role": "user", "content": user_prompt}
        ]

        # –í—ã–∑—ã–≤–∞–µ–º API
        raw_translation = self._call_openai_api(messages)

        if raw_translation:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—ã—Ä–æ–π –æ—Ç–≤–µ—Ç
            translation = raw_translation
            # –£–±–∏—Ä–∞–µ–º markdown —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏
            translation = translation.replace('---\n\n', '').replace('---\n', '').replace('---', '')
            translation = translation.strip()

            # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–µ—Ñ–∏–∫—Å—ã, –∫–æ—Ç–æ—Ä—ã–µ –∏–Ω–æ–≥–¥–∞ –¥–æ–±–∞–≤–ª—è–µ—Ç LLM
            prefixes_to_remove = [
                "–ü–µ—Ä–µ–≤–æ–¥: ", "Translation: ", "–ü–µ—Ä–µ–≤–µ–¥—ë–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç: ",
                "–ü–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç: ", "–†–µ–∑—É–ª—å—Ç–∞—Ç: ", "–û—Ç–≤–µ—Ç: ", "–û—Ç–≤–µ—Ç:\n"
            ]
            for prefix in prefixes_to_remove:
                if translation.startswith(prefix):
                    translation = translation[len(prefix):].strip()
                    break

            # –£–±–∏—Ä–∞–µ–º –≤–Ω–µ—à–Ω–∏–µ –∫–∞–≤—ã—á–∫–∏ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–Ω–∏ –¥–æ–±–∞–≤–ª–µ–Ω—ã LLM (–æ—Ä–∏–≥–∏–Ω–∞–ª –±–µ–∑ –∫–∞–≤—ã—á–µ–∫)
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º: –µ—Å–ª–∏ –æ—Ä–∏–≥–∏–Ω–∞–ª –Ω–µ –Ω–∞—á–∏–Ω–∞–ª—Å—è —Å –∫–∞–≤—ã—á–∫–∏, –Ω–æ –ø–µ—Ä–µ–≤–æ–¥ –æ–±—ë—Ä–Ω—É—Ç –≤ –Ω–∏—Ö - —É–±–∏—Ä–∞–µ–º
            if not text.startswith(("'", '"')):
                # –£–±–∏—Ä–∞–µ–º –æ–¥–Ω—É –ø–∞—Ä—É –≤–Ω–µ—à–Ω–∏—Ö –¥–≤–æ–π–Ω—ã—Ö –∫–∞–≤—ã—á–µ–∫
                if translation.startswith('"') and translation.endswith('"') and len(translation) > 1:
                    translation = translation[1:-1]
                # –£–±–∏—Ä–∞–µ–º –æ–¥–Ω—É –ø–∞—Ä—É –≤–Ω–µ—à–Ω–∏—Ö –æ–¥–∏–Ω–∞—Ä–Ω—ã—Ö –∫–∞–≤—ã—á–µ–∫
                elif translation.startswith("'") and translation.endswith("'") and len(translation) > 1:
                    translation = translation[1:-1]

            # –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø—Ä–æ–±–µ–ª–æ–≤
            translation = translation.strip()
            
            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º escape-–ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏, –µ—Å–ª–∏ –æ–Ω–∏ –±—ã–ª–∏ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª–µ
            # LLM –º–æ–∂–µ—Ç –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å \\n –≤ —Ä–µ–∞–ª—å–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥ —Å—Ç—Ä–æ–∫–∏, –Ω—É–∂–Ω–æ –≤–µ—Ä–Ω—É—Ç—å –æ–±—Ä–∞—Ç–Ω–æ
            if '\\n' in text and '\n' in translation and '\\n' not in translation:
                translation = translation.replace('\n', '\\n')
            if '\\t' in text and '\t' in translation and '\\t' not in translation:
                translation = translation.replace('\t', '\\t')

            # –í–∞–ª–∏–¥–∞—Ü–∏—è (–±–µ–∑ —Å–∞–º–æ–ø—Ä–æ–≤–µ—Ä–∫–∏ - –ø—Ä–∞–≤–∏–ª–∞ –≤ –º–æ–¥–µ–ª–∏)
            errors = self.validator.validate(text, translation)

            if errors:
                print(f"  ‚ö†Ô∏è  –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –¥–ª—è '{text[:50]}...':")
                for error in errors:
                    print(f"      - {error}")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—Ä–∏—Ç–∏—á–Ω—ã–µ –æ—à–∏–±–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –¥–æ–ª–∂–Ω—ã –æ—Ç–∫–ª–æ–Ω–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥
                critical_errors = [
                    "–†–µ–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–≤–æ–¥—ã —Å—Ç—Ä–æ–∫",
                    "–ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ {#}",
                    "–õ–∏—à–Ω–∏–π –ø—Ä–æ–±–µ–ª –ø–µ—Ä–µ–¥ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π"
                ]
                for error in errors:
                    for critical in critical_errors:
                        if critical in error:
                            print(f"  ‚ùå –ö—Ä–∏—Ç–∏—á–Ω–∞—è –æ—à–∏–±–∫–∞ - –ø–µ—Ä–µ–≤–æ–¥ –æ—Ç–∫–ª–æ–Ω—ë–Ω")
                            return (None, raw_translation)

            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–æ—Ä—Ç–µ–∂ (–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥, —Å—ã—Ä–æ–π –æ—Ç–≤–µ—Ç)
            return (translation, raw_translation)

        return (None, None)

    def _save_progress(self, output_file: str, strings: List[Dict], metadata: Optional[Dict], translated: int, failed: int):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ç–µ–∫—É—â–∏–π –ø—Ä–æ–≥—Ä–µ—Å—Å –ø–µ—Ä–µ–≤–æ–¥–∞"""
        if metadata:
            metadata["translated"] = translated
            metadata["failed"] = failed
            metadata["untranslated"] = len(strings) - translated - failed

        output = {
            "metadata": metadata or {},
            "strings": strings
        }

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(output, f, ensure_ascii=False, indent=2)

    def _save_errors(self, output_file: str, error_strings: List[Dict], metadata: Optional[Dict]):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å—Ç—Ä–æ–∫–∏ —Å –æ—à–∏–±–∫–∞–º–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞"""
        if not error_strings:
            return

        # –§–æ—Ä–º–∏—Ä—É–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –¥–ª—è –æ—à–∏–±–æ–∫
        base_name = output_file.rsplit('.', 1)[0]
        error_file = f"{base_name}_errors.json"

        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –æ—à–∏–±–∫–∏, –µ—Å–ª–∏ —Ñ–∞–π–ª –µ—Å—Ç—å
        existing_errors = []
        existing_originals = set()
        
        if os.path.exists(error_file):
            try:
                with open(error_file, 'r', encoding='utf-8') as f:
                    existing_data = json.load(f)
                    existing_errors = existing_data.get('strings', [])
                    existing_originals = {item.get('original', '') for item in existing_errors}
                print(f"  üìù –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –æ—à–∏–±–æ–∫: {len(existing_errors)}")
            except Exception as e:
                print(f"  ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ —Ñ–∞–π–ª–∞ –æ—à–∏–±–æ–∫: {e}")

        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ –æ—à–∏–±–∫–∏ (–±–µ–∑ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤)
        new_errors_count = 0
        for error in error_strings:
            original = error.get('original', '')
            if original not in existing_originals:
                existing_errors.append(error)
                existing_originals.add(original)
                new_errors_count += 1

        error_metadata = metadata.copy() if metadata else {}
        error_metadata["error_count"] = len(existing_errors)
        error_metadata["description"] = "–°—Ç—Ä–æ–∫–∏ —Å –æ—à–∏–±–∫–∞–º–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞"

        output = {
            "metadata": error_metadata,
            "strings": existing_errors
        }

        with open(error_file, 'w', encoding='utf-8') as f:
            json.dump(output, f, ensure_ascii=False, indent=2)

        if new_errors_count > 0:
            print(f"\n‚ö†Ô∏è  –î–æ–±–∞–≤–ª–µ–Ω–æ –Ω–æ–≤—ã—Ö –æ—à–∏–±–æ–∫: {new_errors_count} (–≤—Å–µ–≥–æ: {len(existing_errors)}) –≤ {error_file}")
        else:
            print(f"\n‚úì –ù–æ–≤—ã—Ö –æ—à–∏–±–æ–∫ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ (–≤—Å–µ–≥–æ: {len(existing_errors)})")

    def translate_batch(self, strings: List[Dict], output_file: Optional[str] = None, metadata: Optional[Dict] = None, save_errors: bool = True) -> List[Dict]:
        """–ü–µ—Ä–µ–≤–æ–¥–∏—Ç –ø–∞–∫–µ—Ç —Å—Ç—Ä–æ–∫ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–π —Å—Ç—Ä–æ–∫–∏
        
        Args:
            save_errors: –ï—Å–ª–∏ False, –Ω–µ —Å–æ–∑–¥–∞–µ—Ç —Ñ–∞–π–ª _errors.json
        """

        total = len(strings)
        translated = 0
        failed = 0
        error_strings = []  # –°—Ç—Ä–æ–∫–∏ —Å –æ—à–∏–±–∫–∞–º–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏

        print(f"üîÑ –ù–∞—á–∏–Ω–∞—é –ø–µ—Ä–µ–≤–æ–¥ {total} —Å—Ç—Ä–æ–∫...")

        for idx, string_obj in enumerate(strings):
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —É–∂–µ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–µ
            if string_obj.get("translation", "").strip():
                print(f"  [{idx+1}/{total}] ‚è≠Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω–æ (—É–∂–µ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–æ): {string_obj['original'][:50]}...")
                continue

            original = string_obj["original"]
            context = string_obj.get("context", "")
            speaker_gender = string_obj.get("speaker_gender", "")

            print(f"  [{idx+1}/{total}] üîÑ –ü–µ—Ä–µ–≤–æ–∂—É: {original[:50]}...")

            result = self.translate_single(original, context, speaker_gender)

            if result and result[0]:
                translation, raw_translation = result
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏—é –ü–ï–†–ï–î —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –≤ string_obj
                errors = self.validator.validate(original, translation)
                if errors:
                    # –í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–µ –ø—Ä–æ—à–ª–∞ - —Å–æ—Ö—Ä–∞–Ω—è–µ–º –¢–û–õ–¨–ö–û –≤ error_strings
                    error_obj = string_obj.copy()
                    error_obj["translation"] = translation
                    error_obj["translated_raw"] = raw_translation
                    error_obj["validation_errors"] = errors
                    error_strings.append(error_obj)
                    
                    failed += 1
                    print(f"  [{idx+1}/{total}] ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏:")
                    for error in errors:
                        print(f"      - {error}")
                else:
                    # –í–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–æ—à–ª–∞ - —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ string_obj (–ø–æ–ø–∞–¥—ë—Ç –≤ _translated)
                    # –í—Å—Ç–∞–≤–ª—è–µ–º –ø–æ–ª—è –≤ –Ω—É–∂–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ: translation, translated_raw
                    # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å —Å –Ω—É–∂–Ω—ã–º –ø–æ—Ä—è–¥–∫–æ–º
                    temp_obj = {}
                    for key in string_obj:
                        temp_obj[key] = string_obj[key]
                        if key == "translation" or (key == "original" and "translation" not in string_obj):
                            temp_obj["translation"] = translation
                            temp_obj["translated_raw"] = raw_translation
                    
                    # –ï—Å–ª–∏ translation –Ω–µ –±—ã–ª–æ –¥–æ–±–∞–≤–ª–µ–Ω–æ, –¥–æ–±–∞–≤–ª—è–µ–º –≤ –∫–æ–Ω–µ—Ü
                    if "translation" not in temp_obj:
                        temp_obj["translation"] = translation
                        temp_obj["translated_raw"] = raw_translation
                    
                    string_obj.clear()
                    string_obj.update(temp_obj)
                    
                    translated += 1
                    print(f"  [{idx+1}/{total}] ‚úÖ {translation[:50]}...")
            else:
                # –ü–µ—Ä–µ–≤–æ–¥ –Ω–µ —É–¥–∞–ª—Å—è –∏–ª–∏ –±—ã–ª –æ—Ç–∫–ª–æ–Ω—ë–Ω –∏–∑-–∑–∞ –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö –æ—à–∏–±–æ–∫
                failed += 1
                print(f"  [{idx+1}/{total}] ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–µ—Ä–µ–≤–µ—Å—Ç–∏")
                
                # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Å–ø–∏—Å–æ–∫ –æ—à–∏–±–æ–∫ –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞
                error_obj = string_obj.copy()
                error_obj["validation_errors"] = ["–ü–µ—Ä–µ–≤–æ–¥ –æ—Ç–∫–ª–æ–Ω—ë–Ω –∏–ª–∏ –Ω–µ –ø–æ–ª—É—á–µ–Ω"]
                error_strings.append(error_obj)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–π —Å—Ç—Ä–æ–∫–∏
            if output_file:
                self._save_progress(output_file, strings, metadata, translated, failed)

            # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
            time.sleep(0.5)

        print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"  ‚úÖ –ü–µ—Ä–µ–≤–µ–¥–µ–Ω–æ: {translated}")
        print(f"  ‚ùå –û—à–∏–±–∫–∏: {failed}")
        print(f"  ‚è≠Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω–æ: {total - translated - failed}")
        print(f"  ‚ö†Ô∏è  –° –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è–º–∏: {len(error_strings)}")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –æ—à–∏–±–∫–∞–º–∏ –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª (–µ—Å–ª–∏ —Ä–∞–∑—Ä–µ—à–µ–Ω–æ)
        if save_errors and output_file and error_strings:
            self._save_errors(output_file, error_strings, metadata)

        return strings

    def translate_file(self, input_file: str, output_file: str, save_errors: bool = True):
        """–ü–µ—Ä–µ–≤–æ–¥–∏—Ç —Ñ–∞–π–ª JSON
        
        Args:
            save_errors: –ï—Å–ª–∏ False, –Ω–µ —Å–æ–∑–¥–∞–µ—Ç —Ñ–∞–π–ª _errors.json
        """

        print(f"üìÑ –ó–∞–≥—Ä—É–∂–∞—é: {input_file}")

        with open(input_file, 'r', encoding='utf-8') as f:
            data = json.load(f)

        metadata = data.get("metadata", {})
        strings = data.get("strings", [])

        print(f"üìä –ú–æ–¥—É–ª—å: {metadata.get('module', 'unknown')}")
        print(f"üìä –í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫: {len(strings)}")
        print(f"üìä –ü–µ—Ä–µ–≤–µ–¥–µ–Ω–æ: {metadata.get('translated', 0)}")
        print()

        # –ü–µ—Ä–µ–≤–æ–¥–∏–º —Å –∞–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
        translated_strings = self.translate_batch(strings, output_file, metadata, save_errors)

        print(f"\nüíæ –ü–µ—Ä–µ–≤–æ–¥ –∑–∞–≤–µ—Ä—à–µ–Ω –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {output_file}")


def main():
    parser = argparse.ArgumentParser(description="–ü–µ—Ä–µ–≤–æ–¥ —á–µ—Ä–µ–∑ LLM")
    parser.add_argument("--input", required=True, help="–í—Ö–æ–¥–Ω–æ–π JSON —Ñ–∞–π–ª")
    parser.add_argument("--output", required=True, help="–í—ã—Ö–æ–¥–Ω–æ–π JSON —Ñ–∞–π–ª")
    parser.add_argument("--backend", default="openai", choices=["openai", "ollama"],
                       help="Backend –¥–ª—è LLM")
    parser.add_argument("--api-url", default="http://localhost:8080/v1/chat/completions",
                       help="URL API")
    parser.add_argument("--api-key", default="not-needed",
                       help="API –∫–ª—é—á (–µ—Å–ª–∏ –Ω—É–∂–µ–Ω)")
    parser.add_argument("--model", default="local-model",
                       help="–ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏")
    parser.add_argument("--temperature", type=float, default=0.1,
                       help="Temperature –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏")
    parser.add_argument("--top-p", type=float, default=0.7,
                       help="Top-p sampling")
    parser.add_argument("--max-tokens", type=int, default=2000,
                       help="–ú–∞–∫—Å–∏–º—É–º —Ç–æ–∫–µ–Ω–æ–≤ –≤ –æ—Ç–≤–µ—Ç–µ")
    parser.add_argument("--batch-size", type=int, default=10,
                       help="–†–∞–∑–º–µ—Ä –ø–∞–∫–µ—Ç–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è, –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)")
    parser.add_argument("--max-retries", type=int, default=3,
                       help="–ú–∞–∫—Å–∏–º—É–º –ø–æ–ø—ã—Ç–æ–∫ –ø–æ–≤—Ç–æ—Ä–∞ (–Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è, –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)")
    parser.add_argument("--no-error-file", action="store_true",
                       help="–ù–µ —Å–æ–∑–¥–∞–≤–∞—Ç—å —Ñ–∞–π–ª _errors.json")

    args = parser.parse_args()

    # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    config = TranslationConfig(
        backend=args.backend,
        api_url=args.api_url,
        api_key=args.api_key,
        model=args.model,
        temperature=args.temperature,
        top_p=args.top_p,
        max_tokens=args.max_tokens
    )

    # –°–æ–∑–¥–∞–µ–º –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫
    translator = LLMTranslator(config)

    # –ü–µ—Ä–µ–≤–æ–¥–∏–º —Ñ–∞–π–ª
    translator.translate_file(args.input, args.output, save_errors=not args.no_error_file)

    print("\nüéâ –ì–æ—Ç–æ–≤–æ!")


if __name__ == "__main__":
    main()
