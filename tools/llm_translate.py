#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
–ü–µ—Ä–µ–≤–æ–¥ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ –ª–æ–∫–∞–ª—å–Ω—É—é LLM
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ backends: OpenAI-compatible API, llama.cpp, Ollama
"""

import os
import re
import json
import argparse
import time
from typing import List, Dict, Optional
from dataclasses import dataclass


@dataclass
class TranslationConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞"""
    backend: str = "openai"  # openai, ollama, llamacpp
    api_url: str = "http://localhost:8080/v1/chat/completions"
    api_key: str = "not-needed"
    model: str = "local-model"
    temperature: float = 0.1
    top_p: float = 0.7
    max_tokens: int = 2000
    batch_size: int = 10


class TranslationValidator:
    """–í–∞–ª–∏–¥–∞—Ç–æ—Ä –ø–µ—Ä–µ–≤–æ–¥–æ–≤"""

    @staticmethod
    def validate(original: str, translation: str) -> List[str]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –ø–µ—Ä–µ–≤–æ–¥–∞"""
        errors = []

        if not translation or not translation.strip():
            return errors  # –ü—É—Å—Ç—ã–µ –ø–µ—Ä–µ–≤–æ–¥—ã –Ω–µ –æ—à–∏–±–∫–∞

        # 1. –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –≤ —Ñ–∏–≥—É—Ä–Ω—ã—Ö —Å–∫–æ–±–∫–∞—Ö
        orig_vars_curly = set(re.findall(r'\{(\w+)\}', original))
        trans_vars_curly = set(re.findall(r'\{(\w+)\}', translation))
        if orig_vars_curly != trans_vars_curly:
            errors.append(f"–ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ {{}}: {orig_vars_curly} != {trans_vars_curly}")

        # 2. –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –≤ –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã—Ö —Å–∫–æ–±–∫–∞—Ö
        orig_vars_square = set(re.findall(r'\[(\w+)\]', original))
        trans_vars_square = set(re.findall(r'\[(\w+)\]', translation))
        if orig_vars_square != trans_vars_square:
            errors.append(f"–ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ []: {orig_vars_square} != {trans_vars_square}")

        # 3. –¢–µ–≥–∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        orig_tags = re.findall(r'\{/?(?:color|b|i|u|size|center)[^}]*\}', original)
        trans_tags = re.findall(r'\{/?(?:color|b|i|u|size|center)[^}]*\}', translation)
        if orig_tags != trans_tags:
            errors.append(f"–¢–µ–≥–∏: {orig_tags} != {trans_tags}")

        # 4. –ü–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
        if original.count('\\n') != translation.count('\\n'):
            errors.append(f"\\n: {original.count('\\n')} != {translation.count('\\n')}")

        # 5. –ù–µ—ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏
        if '"' in translation and '\\"' not in translation:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –Ω–µ –≤–Ω–µ—à–Ω–∏–µ –∫–∞–≤—ã—á–∫–∏
            inner_text = translation.strip('"')
            if '"' in inner_text:
                errors.append('–ö–∞–≤—ã—á–∫–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω—ã: \\"')

        return errors


class LLMTranslator:
    """–ü–µ—Ä–µ–≤–æ–¥—á–∏–∫ —á–µ—Ä–µ–∑ LLM"""

    def __init__(self, config: TranslationConfig):
        self.config = config
        self.validator = TranslationValidator()
        # system_prompt –∑–∞–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω - –ø—Ä–∞–≤–∏–ª–∞ –∑–∞—à–∏—Ç—ã –≤ –º–æ–¥–µ–ª—å
        # self.system_prompt = self._create_system_prompt()

    def _call_openai_api(self, messages: List[Dict]) -> Optional[str]:
        """–í—ã–∑–æ–≤ API (OpenAI –∏–ª–∏ Ollama)"""
        try:
            import requests

            if self.config.backend == "ollama":
                # –§–æ—Ä–º–∞—Ç –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è Ollama
                data = {
                    "model": self.config.model,
                    "messages": messages,
                    "options": {
                        "temperature": self.config.temperature,
                        "top_p": self.config.top_p,
                        "num_predict": self.config.max_tokens
                    },
                    "stream": False
                }

                # Ollama –Ω–µ —Ç—Ä–µ–±—É–µ—Ç API –∫–ª—é—á–∞
                headers = {"Content-Type": "application/json"}

                response = requests.post(
                    self.config.api_url,
                    headers=headers,
                    json=data,
                    timeout=300  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ç–∞–π–º–∞—É—Ç –¥–ª—è Ollama
                )

                response.raise_for_status()
                result = response.json()

                # –§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ Ollama
                return result["message"]["content"].strip()

            else:
                # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç OpenAI
                headers = {
                    "Content-Type": "application/json",
                    "Authorization": f"Bearer {self.config.api_key}"
                }

                data = {
                    "model": self.config.model,
                    "messages": messages,
                    "temperature": self.config.temperature,
                    "max_tokens": self.config.max_tokens
                }

                response = requests.post(
                    self.config.api_url,
                    headers=headers,
                    json=data,
                    timeout=120
                )

                response.raise_for_status()
                result = response.json()

                return result["choices"][0]["message"]["content"].strip()

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ API ({self.config.backend}): {e}")
            if hasattr(e, 'response') and hasattr(e.response, 'text'):
                print(f"–û—Ç–≤–µ—Ç —Å–µ—Ä–≤–µ—Ä–∞: {e.response.text}")
            return None

    def should_skip_translation(self, text: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥ —ç—Ç–æ–π —Å—Ç—Ä–æ–∫–∏"""
        # –°–ª—É–∂–µ–±–Ω—ã–µ —Å–ª–æ–≤–∞ Ren'Py
        renpy_keywords = {
            "centered", "left", "right", "top", "bottom",
            "True", "False", "None"
        }

        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ —Å–ª–æ–≤–∞
        if text.strip() in renpy_keywords:
            return True

        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏–µ —Å—Ç—Ä–æ–∫–∏ (1-2 —Å–∏–º–≤–æ–ª–∞)
        if len(text.strip()) <= 2:
            return True

        return False

    def translate_single(self, text: str, context: str = "", speaker_gender: str = "") -> Optional[str]:
        """–ü–µ—Ä–µ–≤–æ–¥–∏—Ç –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É"""

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥
        if self.should_skip_translation(text):
            return text  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π

        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ Instruct
        # –ü—Ä–∞–≤–∏–ª–∞ –ø–µ—Ä–µ–≤–æ–¥–∞ –∑–∞—à–∏—Ç—ã –≤ –º–æ–¥–µ–ª—å, –ø–æ—ç—Ç–æ–º—É –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç–æ–π —Ñ–æ—Ä–º–∞—Ç
        gender_prefix = f"{speaker_gender}: " if speaker_gender else ""
        user_prompt = f'[INST]–ü–µ—Ä–µ–≤–µ–¥–∏ {gender_prefix}"{text}"[/INST]'

        # –î–ª—è Ollama –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫–∞–∫ –æ–±—ã—á–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        messages = [
            {"role": "user", "content": user_prompt}
        ]

        # –í—ã–∑—ã–≤–∞–µ–º API
        translation = self._call_openai_api(messages)

        if translation:
            # –£–±–∏—Ä–∞–µ–º –≤–Ω–µ—à–Ω–∏–µ –∫–∞–≤—ã—á–∫–∏ –µ—Å–ª–∏ LLM –¥–æ–±–∞–≤–∏–ª–∞ –∏—Ö
            translation = translation.strip('"\'')

            # –£–±–∏—Ä–∞–µ–º markdown —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏
            translation = translation.replace('---\n\n', '').replace('---\n', '').replace('---', '')
            translation = translation.strip()

            # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–µ—Ñ–∏–∫—Å—ã, –∫–æ—Ç–æ—Ä—ã–µ –∏–Ω–æ–≥–¥–∞ –¥–æ–±–∞–≤–ª—è–µ—Ç LLM
            prefixes_to_remove = [
                "–ü–µ—Ä–µ–≤–æ–¥: ", "Translation: ", "–ü–µ—Ä–µ–≤–µ–¥—ë–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç: ",
                "–ü–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç: ", "–†–µ–∑—É–ª—å—Ç–∞—Ç: ", "–û—Ç–≤–µ—Ç: ", "–û—Ç–≤–µ—Ç:\n"
            ]
            for prefix in prefixes_to_remove:
                if translation.startswith(prefix):
                    translation = translation[len(prefix):].strip('"\'')
                    break

            # –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞
            translation = translation.strip()

            # –í–∞–ª–∏–¥–∞—Ü–∏—è (–±–µ–∑ —Å–∞–º–æ–ø—Ä–æ–≤–µ—Ä–∫–∏ - –ø—Ä–∞–≤–∏–ª–∞ –≤ –º–æ–¥–µ–ª–∏)
            errors = self.validator.validate(text, translation)

            if errors:
                print(f"  ‚ö†Ô∏è  –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –¥–ª—è '{text[:50]}...':")
                for error in errors:
                    print(f"      - {error}")

            return translation

        return None

    def translate_batch(self, strings: List[Dict]) -> List[Dict]:
        """–ü–µ—Ä–µ–≤–æ–¥–∏—Ç –ø–∞–∫–µ—Ç —Å—Ç—Ä–æ–∫"""

        total = len(strings)
        translated = 0
        failed = 0

        print(f"üîÑ –ù–∞—á–∏–Ω–∞—é –ø–µ—Ä–µ–≤–æ–¥ {total} —Å—Ç—Ä–æ–∫...")

        for idx, string_obj in enumerate(strings):
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —É–∂–µ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–µ
            if string_obj.get("translation", "").strip():
                print(f"  [{idx+1}/{total}] ‚è≠Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω–æ (—É–∂–µ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–æ): {string_obj['original'][:50]}...")
                continue

            original = string_obj["original"]
            context = string_obj.get("context", "")
            speaker_gender = string_obj.get("speaker_gender", "")

            print(f"  [{idx+1}/{total}] üîÑ –ü–µ—Ä–µ–≤–æ–∂—É: {original[:50]}...")

            translation = self.translate_single(original, context, speaker_gender)

            if translation:
                string_obj["translation"] = translation
                translated += 1
                print(f"  [{idx+1}/{total}] ‚úÖ {translation[:50]}...")
            else:
                failed += 1
                print(f"  [{idx+1}/{total}] ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–µ—Ä–µ–≤–µ—Å—Ç–∏")

            # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
            time.sleep(0.5)

        print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"  ‚úÖ –ü–µ—Ä–µ–≤–µ–¥–µ–Ω–æ: {translated}")
        print(f"  ‚ùå –û—à–∏–±–∫–∏: {failed}")
        print(f"  ‚è≠Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω–æ: {total - translated - failed}")

        return strings

    def translate_file(self, input_file: str, output_file: str):
        """–ü–µ—Ä–µ–≤–æ–¥–∏—Ç —Ñ–∞–π–ª JSON"""

        print(f"üìÑ –ó–∞–≥—Ä—É–∂–∞—é: {input_file}")

        with open(input_file, 'r', encoding='utf-8') as f:
            data = json.load(f)

        metadata = data.get("metadata", {})
        strings = data.get("strings", [])

        print(f"üìä –ú–æ–¥—É–ª—å: {metadata.get('module', 'unknown')}")
        print(f"üìä –í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫: {len(strings)}")
        print(f"üìä –ü–µ—Ä–µ–≤–µ–¥–µ–Ω–æ: {metadata.get('translated', 0)}")
        print()

        # –ü–µ—Ä–µ–≤–æ–¥–∏–º
        translated_strings = self.translate_batch(strings)

        # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        translated_count = sum(1 for s in translated_strings if s.get("translation", "").strip())
        metadata["translated"] = translated_count
        metadata["untranslated"] = len(strings) - translated_count

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        output = {
            "metadata": metadata,
            "strings": translated_strings
        }

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(output, f, ensure_ascii=False, indent=2)

        print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤: {output_file}")


def main():
    parser = argparse.ArgumentParser(description="–ü–µ—Ä–µ–≤–æ–¥ —á–µ—Ä–µ–∑ LLM")
    parser.add_argument("--input", required=True, help="–í—Ö–æ–¥–Ω–æ–π JSON —Ñ–∞–π–ª")
    parser.add_argument("--output", required=True, help="–í—ã—Ö–æ–¥–Ω–æ–π JSON —Ñ–∞–π–ª")
    parser.add_argument("--backend", default="openai", choices=["openai", "ollama"],
                       help="Backend –¥–ª—è LLM")
    parser.add_argument("--api-url", default="http://localhost:8080/v1/chat/completions",
                       help="URL API")
    parser.add_argument("--api-key", default="not-needed",
                       help="API –∫–ª—é—á (–µ—Å–ª–∏ –Ω—É–∂–µ–Ω)")
    parser.add_argument("--model", default="local-model",
                       help="–ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏")
    parser.add_argument("--temperature", type=float, default=0.1,
                       help="Temperature –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏")
    parser.add_argument("--top-p", type=float, default=0.7,
                       help="Top-p sampling")
    parser.add_argument("--max-tokens", type=int, default=2000,
                       help="–ú–∞–∫—Å–∏–º—É–º —Ç–æ–∫–µ–Ω–æ–≤ –≤ –æ—Ç–≤–µ—Ç–µ")
    parser.add_argument("--batch-size", type=int, default=10,
                       help="–†–∞–∑–º–µ—Ä –ø–∞–∫–µ—Ç–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è, –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)")
    parser.add_argument("--max-retries", type=int, default=3,
                       help="–ú–∞–∫—Å–∏–º—É–º –ø–æ–ø—ã—Ç–æ–∫ –ø–æ–≤—Ç–æ—Ä–∞ (–Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è, –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)")

    args = parser.parse_args()

    # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    config = TranslationConfig(
        backend=args.backend,
        api_url=args.api_url,
        api_key=args.api_key,
        model=args.model,
        temperature=args.temperature,
        top_p=args.top_p,
        max_tokens=args.max_tokens
    )

    # –°–æ–∑–¥–∞–µ–º –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫
    translator = LLMTranslator(config)

    # –ü–µ—Ä–µ–≤–æ–¥–∏–º —Ñ–∞–π–ª
    translator.translate_file(args.input, args.output)

    print("\nüéâ –ì–æ—Ç–æ–≤–æ!")


if __name__ == "__main__":
    main()
