#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ñ–∞–π–ª–æ–≤ –ø–µ—Ä–µ–≤–æ–¥–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —á–µ—Ä–µ–∑ LLM (–≤–µ—Ä—Å–∏—è 2)
–° –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞—Ö
–†–∞–±–æ—Ç–∞–µ—Ç —Å –∏—Å—Ö–æ–¥–Ω—ã–º–∏ .rpy —Ñ–∞–π–ª–∞–º–∏ –∏–∑ extracted_scripts/
"""

import os
import re
import json
import argparse
from datetime import datetime
from typing import List, Dict, Tuple, Set, Optional
from collections import defaultdict


class TranslationPreparerV2:
    # –°–ª—É–∂–µ–±–Ω—ã–µ —Å–ª–æ–≤–∞ RenPy, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ —è–≤–ª—è—é—Ç—Å—è –ø–µ—Ä—Å–æ–Ω–∞–∂–∞–º–∏
    RENPY_KEYWORDS = {
        'if', 'else', 'elif', 'while', 'for', 'pass', 'return', 'jump', 'call',
        'menu', 'centered', 'extend', 'nvl', 'scene', 'show', 'hide', 'with',
        'window', 'play', 'stop', 'pause', 'define', 'default', 'label', 'init',
        'python', 'transform', 'image', 'screen', 'style', 'translate', 'narrator',
        'pov', 'variant', 'textbutton', 'text_selected_color', 'text_hover_color',
        'text_font', 'text_color', 'text', 'style_suffix', 'layout',
        'mousewheel', 'scrollbars', 'size_group', 'style_group', 'style_prefix',
        'add', 'alt', 'auto','background', 'draggable', 'font', 'foreground',
        'hover_background', 'id', 'idle', 'key', 'thumb', 'fmw'
    }

    def __init__(self):
        self.strings = []
        self.character_entities = set()  # –í—Å–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Å—É—â–Ω–æ—Å—Ç–∏ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π

    def parse_rpy_source(self, file_path: str) -> Tuple[List[Dict], Set[str]]:
        """–ü–∞—Ä—Å–∏—Ç –∏—Å—Ö–æ–¥–Ω—ã–π .rpy —Ñ–∞–π–ª –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –ø–µ—Ä–µ–≤–æ–¥–∏–º—ã–µ —Å—Ç—Ä–æ–∫–∏ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π"""

        if not os.path.exists(file_path):
            raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")

        with open(file_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()

        strings = []
        character_entities = set()
        current_speaker = None  # –¢–µ–∫—É—â–∏–π –≥–æ–≤–æ—Ä—è—â–∏–π (–∏–∑ show –∏–ª–∏ –ø—Ä–µ–¥—ã–¥—É—â–µ–π —Ä–µ–ø–ª–∏–∫–∏)
        seen_texts = set()  # –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤

        idx = 0
        for line_num, line in enumerate(lines, 1):
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∏ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
            stripped = line.strip()
            if not stripped or stripped.startswith('#'):
                continue

            # –ö–æ–º–∞–Ω–¥–∞ show - –æ–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–µ–∫—É—â–µ–≥–æ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞
            show_match = re.match(r'\s+show\s+(\w+)', line)
            if show_match:
                current_speaker = show_match.group(1)
                continue

            # –°–∫—Ä—ã–≤–∞–µ–º –ø–µ—Ä—Å–æ–Ω–∞–∂–∞
            hide_match = re.match(r'\s+hide\s+(\w+)', line)
            if hide_match:
                if current_speaker == hide_match.group(1):
                    current_speaker = None
                continue

            # –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è textbutton (–î–û–õ–ñ–ï–ù –ë–´–¢–¨ –ü–ï–†–ï–î dialog_match!)
            # –§–æ—Ä–º–∞—Ç: textbutton "—Ç–µ–∫—Å—Ç": –∏–ª–∏ textbutton '—Ç–µ–∫—Å—Ç':
            textbutton_match = re.match(r'\s+textbutton\s+["\'](.+?)["\']\s*:', line)
            if textbutton_match:
                text = textbutton_match.group(1)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—É—é –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é —Å—Ç—Ä–æ–∫—É –¥–ª—è —É–ø–∞–∫–æ–≤–∫–∏
                original_line = line.strip()
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å–ª–∏ –ø–æ—Å–ª–µ —Ç–µ–∫—Å—Ç–∞ –∏–¥—ë—Ç —É—Å–ª–æ–≤–∏–µ
                remaining_line = line[textbutton_match.end():]
                has_condition = ('==' in remaining_line or 'True' in remaining_line or 'False' in remaining_line)
                
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ –∏ –æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏–µ —Å—Ç—Ä–æ–∫–∏
                if not text.strip() or len(text.strip()) < 2:
                    continue
                
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º hex —Ü–≤–µ—Ç–∞
                if re.match(r'^#[0-9a-fA-F]+$', text.strip()):
                    continue
                
                analysis = self._analyze_text(text)
                
                string_obj = {
                    "id": idx,
                    "line": line_num,
                    "file": os.path.basename(file_path),
                    "speaker": "ui",
                    "speaker_prefix": "ui",
                    "original": text,
                    "translation": "",
                    "context": "ui",
                    "tags": analysis["tags"],
                    "variables_curly": analysis["variables_curly"],
                    "variables_square": analysis["variables_square"],
                    "special_chars": analysis["special_chars"]
                }
                
                # –ï—Å–ª–∏ –µ—Å—Ç—å —É—Å–ª–æ–≤–∏–µ - —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—É—é —Å—Ç—Ä–æ–∫—É –¥–ª—è —É–ø–∞–∫–æ–≤–∫–∏
                if has_condition:
                    string_obj["original_full"] = original_line
                
                strings.append(string_obj)
                
                idx += 1
                continue

            # –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è menu items
            # –§–æ—Ä–º–∞—Ç: "—Ç–µ–∫—Å—Ç": –∏–ª–∏ '—Ç–µ–∫—Å—Ç': (–º–æ–∂–µ—Ç –±—ã—Ç—å —Å —É—Å–ª–æ–≤–∏–µ–º –º–µ–∂–¥—É –∫–∞–≤—ã—á–∫–æ–π –∏ –¥–≤–æ–µ—Ç–æ—á–∏–µ–º)
            # –õ–æ–≤–∏–º –¥–≤–æ–π–Ω—ã–µ –∏ –æ–¥–∏–Ω–∞—Ä–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏ –æ—Ç–¥–µ–ª—å–Ω–æ, —á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ—Å–µ–∫–∞–ª–∏—Å—å
            menu_match = re.match(r'\s+"([^"]+)".*:$|' + r'\s+\'([^\']+)\'.*:$', line)
            if menu_match:
                # group(1) –¥–ª—è –¥–≤–æ–π–Ω—ã—Ö –∫–∞–≤—ã—á–µ–∫, group(2) –¥–ª—è –æ–¥–∏–Ω–∞—Ä–Ω—ã—Ö
                text = menu_match.group(1) if menu_match.group(1) else menu_match.group(2)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—É—é –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é —Å—Ç—Ä–æ–∫—É –¥–ª—è —É–ø–∞–∫–æ–≤–∫–∏
                original_line = line.strip()
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å–ª–∏ –≤ —Å—Ç—Ä–æ–∫–µ –µ—Å—Ç—å —É—Å–ª–æ–≤–∏–µ –º–µ–∂–¥—É –∫–∞–≤—ã—á–∫–æ–π –∏ –¥–≤–æ–µ—Ç–æ—á–∏–µ–º
                # –ù–∞—Ö–æ–¥–∏–º –ø–æ–∑–∏—Ü–∏—é –∑–∞–∫—Ä—ã–≤–∞—é—â–µ–π –∫–∞–≤—ã—á–∫–∏ –∏ –¥–≤–æ–µ—Ç–æ—á–∏—è
                if text:
                    # –ò—â–µ–º —á—Ç–æ –∏–¥—ë—Ç –ø–æ—Å–ª–µ –∑–∞–∫—Ä—ã–≤–∞—é—â–µ–π –∫–∞–≤—ã—á–∫–∏ –¥–æ –¥–≤–æ–µ—Ç–æ—á–∏—è
                    quote_char = '"' if menu_match.group(1) else "'"
                    after_quote_pos = line.find(quote_char + text + quote_char) + len(quote_char + text + quote_char)
                    between_quote_and_colon = line[after_quote_pos:]
                    has_condition = ('==' in between_quote_and_colon or 'True' in between_quote_and_colon or 'False' in between_quote_and_colon)
                else:
                    has_condition = False
                
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ –∏ –æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Å—Ç—Ä–æ–∫–∏
                if not text.strip() or len(text.strip()) < 2:
                    continue
                
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Å—Ç—Ä–æ–∫–∏ (hex —Ü–≤–µ—Ç–∞, —á–∏—Å–ª–∞)
                if re.match(r'^#[0-9a-fA-F]+$', text.strip()):
                    continue
                
                analysis = self._analyze_text(text)
                
                string_obj = {
                    "id": idx,
                    "line": line_num,
                    "file": os.path.basename(file_path),
                    "speaker": "menu",
                    "speaker_prefix": "menu",
                    "original": text,
                    "translation": "",
                    "context": "menu",
                    "tags": analysis["tags"],
                    "variables_curly": analysis["variables_curly"],
                    "variables_square": analysis["variables_square"],
                    "special_chars": analysis["special_chars"]
                }
                
                # –ï—Å–ª–∏ –µ—Å—Ç—å —É—Å–ª–æ–≤–∏–µ - —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—É—é —Å—Ç—Ä–æ–∫—É –¥–ª—è —É–ø–∞–∫–æ–≤–∫–∏
                if has_condition:
                    string_obj["original_full"] = original_line
                
                strings.append(string_obj)
                
                idx += 1
                continue

            # –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–π –ø–µ—Ä–µ–≤–æ–¥–∞ _("—Ç–µ–∫—Å—Ç")
            translate_func_match = re.search(r'_\("([^"]+)"\)', line)
            if translate_func_match:
                text = translate_func_match.group(1)
                
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ –∏ –æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏–µ —Å—Ç—Ä–æ–∫–∏
                if not text.strip() or len(text.strip()) < 2:
                    continue
                
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º hex —Ü–≤–µ—Ç–∞
                if re.match(r'^#[0-9a-fA-F]+$', text.strip()):
                    continue
                
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
                if text in seen_texts:
                    continue
                
                seen_texts.add(text)
                analysis = self._analyze_text(text)
                
                strings.append({
                    "id": idx,
                    "line": line_num,
                    "file": os.path.basename(file_path),
                    "speaker": "system",
                    "speaker_prefix": "system",
                    "original": text,
                    "translation": "",
                    "context": "text",
                    "tags": analysis["tags"],
                    "variables_curly": analysis["variables_curly"],
                    "variables_square": analysis["variables_square"],
                    "special_chars": analysis["special_chars"]
                })
                
                idx += 1
                continue

            # –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è text_color –∏ –¥—Ä—É–≥–∏—Ö –∞—Ç—Ä–∏–±—É—Ç–æ–≤ (–ø—Ä–æ–ø—É—Å–∫–∞–µ–º)
            if re.match(r'\s+(text_color|text_hover_color|text_selected_color|text_font)\s+', line):
                continue

            # –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –¥–∏–∞–ª–æ–≥–æ–≤ —Å —è–≤–Ω—ã–º —É–∫–∞–∑–∞–Ω–∏–µ–º –ø–µ—Ä—Å–æ–Ω–∞–∂–∞
            # –§–æ—Ä–º–∞—Ç: –ø–µ—Ä—Å–æ–Ω–∞–∂ [talk] "—Ç–µ–∫—Å—Ç" –∏–ª–∏ centered "—Ç–µ–∫—Å—Ç" –∏–ª–∏ extend "—Ç–µ–∫—Å—Ç"
            dialog_match = re.match(r'\s+(\w+)\s+(?:talk\s+)?"([^"]*)"', line)
            if dialog_match:
                speaker = dialog_match.group(1)
                text = dialog_match.group(2)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—É—é –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é —Å—Ç—Ä–æ–∫—É (–≤–∫–ª—é—á–∞—è —É—Å–ª–æ–≤–∏–µ) –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —É–ø–∞–∫–æ–≤–∫–∏
                # –ù–æ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç –≤ –∫–∞–≤—ã—á–∫–∞—Ö
                original_line = line.strip()
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å–ª–∏ –≤ —Å—Ç—Ä–æ–∫–µ –µ—Å—Ç—å == –∏–ª–∏ True/False –ø–æ—Å–ª–µ —Ç–µ–∫—Å—Ç–∞, —ç—Ç–æ —É—Å–ª–æ–≤–∏–µ
                remaining_line = line[dialog_match.end():]
                has_condition = ('==' in remaining_line or 'True' in remaining_line or 'False' in remaining_line)
                
                # –ï—Å–ª–∏ –µ—Å—Ç—å —É—Å–ª–æ–≤–∏–µ - —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—É—é —Å—Ç—Ä–æ–∫—É –≤ metadata –¥–ª—è —É–ø–∞–∫–æ–≤–∫–∏
                # –ü—Ä–∏ —É–ø–∞–∫–æ–≤–∫–µ –±—É–¥–µ–º –∏—Å–∫–∞—Ç—å –ø–æ —ç—Ç–æ–π –ø–æ–ª–Ω–æ–π —Å—Ç—Ä–æ–∫–µ –∏ –∑–∞–º–µ–Ω—è—Ç—å —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç –≤ –∫–∞–≤—ã—á–∫–∞—Ö

                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
                if not text.strip():
                    continue

                # –ï—Å–ª–∏ —ç—Ç–æ —Å–ª—É–∂–µ–±–Ω–æ–µ —Å–ª–æ–≤–æ RenPy, —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—Å—Ç –Ω–æ –Ω–µ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞
                if speaker in self.RENPY_KEYWORDS:
                    analysis = self._analyze_text(text)
                    
                    string_obj = {
                        "id": idx,
                        "line": line_num,
                        "file": os.path.basename(file_path),
                        "speaker": current_speaker if current_speaker else "narrator",
                        "speaker_prefix": self._get_speaker_prefix(current_speaker) if current_speaker else "narrator",
                        "original": text,
                        "translation": "",
                        "context": self._detect_context(text, current_speaker),
                        "tags": analysis["tags"],
                        "variables_curly": analysis["variables_curly"],
                        "variables_square": analysis["variables_square"],
                        "special_chars": analysis["special_chars"]
                    }
                    
                    # –ï—Å–ª–∏ –µ—Å—Ç—å —É—Å–ª–æ–≤–∏–µ - —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—É—é —Å—Ç—Ä–æ–∫—É –¥–ª—è —É–ø–∞–∫–æ–≤–∫–∏
                    if has_condition:
                        string_obj["original_full"] = original_line
                    
                    strings.append(string_obj)
                    
                    idx += 1
                    continue

                character_entities.add(speaker)

                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç
                analysis = self._analyze_text(text)

                string_obj = {
                    "id": idx,
                    "line": line_num,
                    "file": os.path.basename(file_path),
                    "speaker": speaker,
                    "speaker_prefix": self._get_speaker_prefix(speaker),
                    "original": text,
                    "translation": "",
                    "context": self._detect_context(text, speaker),
                    "tags": analysis["tags"],
                    "variables_curly": analysis["variables_curly"],
                    "variables_square": analysis["variables_square"],
                    "special_chars": analysis["special_chars"]
                }
                
                # –ï—Å–ª–∏ –µ—Å—Ç—å —É—Å–ª–æ–≤–∏–µ - —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—É—é —Å—Ç—Ä–æ–∫—É –¥–ª—è —É–ø–∞–∫–æ–≤–∫–∏
                if has_condition:
                    string_obj["original_full"] = original_line
                
                strings.append(string_obj)

                idx += 1
                current_speaker = speaker
                continue

            # –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –∞–Ω–æ–Ω–∏–º–Ω—ã—Ö –¥–∏–∞–ª–æ–≥–æ–≤ (–ø–æ–≤–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ)
            # –§–æ—Ä–º–∞—Ç: "—Ç–µ–∫—Å—Ç" (–ù–ï –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –Ω–∞ :, –∏–Ω–∞—á–µ —ç—Ç–æ menu item)
            anon_match = re.match(r'\s+"([^"]*)"', line)
            if anon_match:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ –ù–ï menu item (–Ω–µ –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –Ω–∞ :)
                if line.strip().endswith(':'):
                    # –≠—Ç–æ menu item, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º - –æ–Ω —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω –≤—ã—à–µ
                    continue
                
                text = anon_match.group(1)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—É—é –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é —Å—Ç—Ä–æ–∫—É –¥–ª—è —É–ø–∞–∫–æ–≤–∫–∏
                original_line = line.strip()
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å–ª–∏ –ø–æ—Å–ª–µ —Ç–µ–∫—Å—Ç–∞ –∏–¥—ë—Ç —É—Å–ª–æ–≤–∏–µ
                remaining_line = line[anon_match.end():]
                has_condition = ('==' in remaining_line or 'True' in remaining_line or 'False' in remaining_line)

                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –∏ –∫–æ—Ä–æ—Ç–∫–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Å—Ç—Ä–æ–∫–∏
                if not text.strip() or len(text.strip()) < 3:
                    continue
                
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º hex —Ü–≤–µ—Ç–∞
                if re.match(r'^#[0-9a-fA-F]+$', text.strip()):
                    continue

                analysis = self._analyze_text(text)

                string_obj = {
                    "id": idx,
                    "line": line_num,
                    "file": os.path.basename(file_path),
                    "speaker": current_speaker if current_speaker else "narrator",
                    "speaker_prefix": self._get_speaker_prefix(current_speaker) if current_speaker else "narrator",
                    "original": text,
                    "translation": "",
                    "context": self._detect_context(text, current_speaker),
                    "tags": analysis["tags"],
                    "variables_curly": analysis["variables_curly"],
                    "variables_square": analysis["variables_square"],
                    "special_chars": analysis["special_chars"]
                }
                
                # –ï—Å–ª–∏ –µ—Å—Ç—å —É—Å–ª–æ–≤–∏–µ - —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—É—é —Å—Ç—Ä–æ–∫—É –¥–ª—è —É–ø–∞–∫–æ–≤–∫–∏
                if has_condition:
                    string_obj["original_full"] = original_line
                
                strings.append(string_obj)

                idx += 1
                continue

        return strings, character_entities

    def _get_speaker_prefix(self, speaker: Optional[str]) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø—Ä–µ—Ñ–∏–∫—Å –ø–µ—Ä—Å–æ–Ω–∞–∂–∞ (n = narrator)"""
        if not speaker:
            return "narrator"

        if speaker.startswith('n') and len(speaker) > 1:
            return 'n'  # nprincess, nmaid –∏ —Ç.–¥.

        return speaker

    def _analyze_text(self, text: str) -> Dict:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–≥–∏, –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ, —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã"""

        # –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –≤ —Ñ–∏–≥—É—Ä–Ω—ã—Ö —Å–∫–æ–±–∫–∞—Ö (–≤–∫–ª—é—á–∞—è {#variable})
        variables_curly = re.findall(r'\{#?(\w+)\}', text)

        # –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –≤ –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã—Ö —Å–∫–æ–±–∫–∞—Ö (–≤–∫–ª—é—á–∞—è —Å–ª–æ–∂–Ω—ã–µ —Ç–∏–ø–∞ [namepov!tc])
        variables_square = re.findall(r'\[([^\]]+)\]', text)

        # –¢–µ–≥–∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        tags = re.findall(r'\{/?(?:color|b|i|u|size|center|w|nw|p|fast)[^}]*\}', text)

        # –°–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã (–∏—â–µ–º –±—É–∫–≤–∞–ª—å–Ω—ã–µ escape-–ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏, –∫–∞–∫ –æ–Ω–∏ –∑–∞–ø–∏—Å–∞–Ω—ã –≤ .rpy)
        # –í .rpy —Ñ–∞–π–ª–∞—Ö escape-–ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∑–∞–ø–∏—Å–∞–Ω—ã –∫–∞–∫ \\n (–¥–≤–∞ —Å–∏–º–≤–æ–ª–∞)
        special_chars = {
            "newlines": text.count('\\n'),
            "tabs": text.count('\\t'),
            "escaped_quotes": text.count('\\"'),
            "has_formatting": bool(tags)
        }

        return {
            "variables_curly": variables_curly,
            "variables_square": variables_square,
            "tags": tags,
            "special_chars": special_chars
        }

    def _detect_context(self, text: str, speaker: Optional[str]) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å—Ç—Ä–æ–∫–∏"""

        # –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ –æ–±—ã—á–Ω–æ –∫–æ—Ä–æ—Ç–∫–∏–µ
        if len(text) < 20 and not any(c in text for c in '.!?'):
            return "ui"

        # –ü–æ–≤–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ (narrator prefix)
        if speaker and speaker.startswith('n') and len(speaker) > 1:
            return "narration"

        # –î–∏–∞–ª–æ–≥–∏ –æ–±—ã—á–Ω–æ —Å–æ–¥–µ—Ä–∂–∞—Ç –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
        if any(c in text for c in '.!?'):
            return "dialogue"

        return "text"

    def save_character_map(self, character_entities: Set[str], output_file: str):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç map –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –≤ JSON —Ñ–∞–π–ª –¥–ª—è –ø—Ä–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –ø–æ–ª–∞"""

        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é, –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        dir_name = os.path.dirname(output_file)
        os.makedirs(dir_name, exist_ok=True)
        
        # –ü—É—Ç—å –∫ –æ—Å–Ω–æ–≤–Ω–æ–º—É —Ñ–∞–π–ª—É (–±–µ–∑ –¥–∞—Ç—ã)
        main_file = output_file
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –∫–∞—Ä—Ç—É –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
        existing_map = {}
        if os.path.exists(main_file):
            try:
                with open(main_file, 'r', encoding='utf-8') as f:
                    existing_map = json.load(f)
                print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∞—è –∫–∞—Ä—Ç–∞: {main_file}")
            except Exception as e:
                print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –∫–∞—Ä—Ç—ã: {e}")

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –Ω–æ–≤—ã–µ –ø–µ—Ä—Å–æ–Ω–∞–∂–∏ –ø–æ –±–∞–∑–æ–≤–æ–º—É –∏–º–µ–Ω–∏ (–±–µ–∑ –ø—Ä–µ—Ñ–∏–∫—Å–∞ n)
        new_character_map = {}
        all_character_map = {}

        for entity in sorted(character_entities):
            base_name = entity.lstrip('n') if entity.startswith('n') and len(entity) > 1 else entity

            # –î–æ–±–∞–≤–ª—è–µ–º –≤ –æ–±—â—É—é –∫–∞—Ä—Ç—É
            if base_name not in all_character_map:
                all_character_map[base_name] = {
                    "entities": [],
                    "gender": "",
                    "notes": ""
                }
            all_character_map[base_name]["entities"].append(entity)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –ø–µ—Ä—Å–æ–Ω–∞–∂ –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –∫–∞—Ä—Ç–µ
            if base_name not in existing_map:
                # –ù–æ–≤—ã–π –ø–µ—Ä—Å–æ–Ω–∞–∂ - –¥–æ–±–∞–≤–ª—è–µ–º –≤ –∫–∞—Ä—Ç—É –Ω–æ–≤—ã—Ö
                if base_name not in new_character_map:
                    new_character_map[base_name] = {
                        "entities": [],
                        "gender": "",
                        "notes": ""
                    }
                new_character_map[base_name]["entities"].append(entity)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã—Ö –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –≤ —Ñ–∞–π–ª —Å –¥–∞—Ç–æ–π
        if new_character_map:
            base_name_file = os.path.basename(output_file)
            name, ext = os.path.splitext(base_name_file)
            
            # –§–æ—Ä–º–∞—Ç –¥–∞—Ç—ã: –¥–µ–Ω—å.–º–µ—Å—è—Ü.–≥–æ–¥-—á–∞—Å:–º–∏–Ω—É—Ç–∞:—Å–µ–∫—É–Ω–¥–∞
            date_str = datetime.now().strftime("%d.%m.%Y-%H:%M:%S")
            new_file = os.path.join(dir_name, f"{name}_{date_str}{ext}")
            
            with open(new_file, 'w', encoding='utf-8') as f:
                json.dump(new_character_map, f, ensure_ascii=False, indent=2)
            
            print(f"üíæ –ù–æ–≤—ã–µ –ø–µ—Ä—Å–æ–Ω–∞–∂–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {new_file}")
            print(f"   –ù–æ–≤—ã—Ö –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π: {len(new_character_map)}")
            print(f"   –ù–æ–≤—ã—Ö —Å—É—â–Ω–æ—Å—Ç–µ–π: {sum(len(v['entities']) for v in new_character_map.values())}")
        else:
            print(f"‚úÖ –ù–æ–≤—ã—Ö –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ")

        print(f"üìä –í—Å–µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π: {len(all_character_map)}")
        print(f"üìä –í—Å–µ–≥–æ —Å—É—â–Ω–æ—Å—Ç–µ–π: {len(character_entities)}")

    def load_character_map(self, character_map_file: str) -> Dict[str, str]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç map –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å entity -> gender"""

        if not os.path.exists(character_map_file):
            return {}

        with open(character_map_file, 'r', encoding='utf-8') as f:
            character_map = json.load(f)

        # –°–æ–∑–¥–∞–µ–º –ø–ª–æ—Å–∫–∏–π —Å–ª–æ–≤–∞—Ä—å entity -> gender
        entity_gender = {}
        for base_name, info in character_map.items():
            gender = info.get("gender", "")
            for entity in info["entities"]:
                entity_gender[entity] = gender

        return entity_gender

    def enrich_with_gender(self, strings: List[Dict], entity_gender: Dict[str, str]):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–ª–µ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞ –≤ —Å—Ç—Ä–æ–∫–∏"""

        for string in strings:
            speaker = string.get("speaker", "")
            string["speaker_gender"] = entity_gender.get(speaker, "unknown")

    def prepare_module(self, module_file: str, output_file: str,
                      character_map_file: Optional[str] = None,
                      save_char_map: bool = True):
        """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –º–æ–¥—É–ª—å –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞"""

        print(f"üìÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª: {module_file}")

        strings, character_entities = self.parse_rpy_source(module_file)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞—Ä—Ç—É –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π, –µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è
        if save_char_map:
            if character_map_file:
                char_map_output = character_map_file
            else:
                # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ data/characters.json
                char_map_output = os.path.join(os.path.dirname(os.path.dirname(output_file)), 'data', 'characters.json')
            self.save_character_map(character_entities, char_map_output)

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–ª–µ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π, –µ—Å–ª–∏ —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        entity_gender = {}
        if character_map_file and os.path.exists(character_map_file):
            entity_gender = self.load_character_map(character_map_file)
            self.enrich_with_gender(strings, entity_gender)
            print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ–ª–µ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π")

        # –ü–æ–¥—Å—á–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        total = len(strings)

        metadata = {
            "source_file": os.path.basename(module_file),
            "source_path": module_file,
            "total_strings": total,
            "character_count": len(character_entities),
            "characters": list(sorted(character_entities)),
            "source_language": "en",
            "target_language": "ru"
        }

        output = {
            "metadata": metadata,
            "strings": strings
        }

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º JSON
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(output, f, ensure_ascii=False, indent=2)

        print(f"‚úÖ –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ: {total} —Å—Ç—Ä–æ–∫")
        print(f"   –ü–µ—Ä—Å–æ–Ω–∞–∂–µ–π: {len(character_entities)}")
        print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤: {output_file}")

        return output

    def prepare_batch(self, source_dir: str, output_dir: str,
                     pattern: str = "*.rpy",
                     character_map_file: Optional[str] = None):
        """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –ø–∞–∫–µ—Ç –∏—Å—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""

        import glob

        if not os.path.exists(output_dir):
            os.makedirs(output_dir)

        source_files = glob.glob(os.path.join(source_dir, pattern))

        print(f"üîç –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(source_files)}")

        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ—Ö –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –∏–∑ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤
        all_characters = set()

        for source_file in source_files:
            basename = os.path.basename(source_file).replace('.rpy', '_v2.json')
            output_file = os.path.join(output_dir, basename)

            try:
                result = self.prepare_module(
                    source_file,
                    output_file,
                    character_map_file=character_map_file,
                    save_char_map=False  # –ù–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–π–ª–∞
                )
                all_characters.update(result["metadata"]["characters"])
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {source_file}: {e}")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—â—É—é –∫–∞—Ä—Ç—É –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π
        if character_map_file:
            self.save_character_map(all_characters, character_map_file)

        print(f"\nüéâ –ì–æ—Ç–æ–≤–æ! –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(source_files)}")
        print(f"   –í—Å–µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π: {len(all_characters)}")


def main():
    parser = argparse.ArgumentParser(
        description="–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–æ–≤ –¥–ª—è LLM (v2 —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:

  # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
  python llm_translate_prepare_v2.py --source ../extracted_scripts/c1.rpy --output ../temp_files/c1_v2.json

  # –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å —Å–æ–∑–¥–∞–Ω–∏–µ–º –∫–∞—Ä—Ç—ã –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π
  python llm_translate_prepare_v2.py --batch ../extracted_scripts --batch-output ../temp_files/llm_json_v2 --character-map ../data/characters.json

  # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –∫–∞—Ä—Ç—ã –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π
  python llm_translate_prepare_v2.py --source ../extracted_scripts/c1.rpy --output ../temp_files/c1_v2.json --character-map ../data/characters.json

–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: –§–∞–π–ª –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è —Å –¥–∞—Ç–æ–π, –Ω–∞–ø—Ä–∏–º–µ—Ä: characters_11.10.2025-23:59:59.json
        """
    )

    parser.add_argument("--source", help="–ü—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É .rpy —Ñ–∞–π–ª—É")
    parser.add_argument("--output", help="–ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É JSON —Ñ–∞–π–ª—É")
    parser.add_argument("--batch", help="–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤—Å–µ —Ñ–∞–π–ª—ã –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏")
    parser.add_argument("--batch-output", default="../temp_files/llm_json_v2",
                       help="–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –≤—ã—Ö–æ–¥–Ω—ã—Ö JSON (–ø—Ä–∏ --batch)")
    parser.add_argument("--pattern", default="*.rpy",
                       help="–ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ñ–∞–π–ª–æ–≤ (–ø—Ä–∏ --batch)")
    parser.add_argument("--character-map",
                       help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –∫–∞—Ä—Ç–æ–π –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π (–¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è)")

    args = parser.parse_args()

    preparer = TranslationPreparerV2()

    if args.batch:
        preparer.prepare_batch(
            args.batch,
            args.batch_output,
            args.pattern,
            character_map_file=args.character_map
        )
    elif args.source and args.output:
        preparer.prepare_module(
            args.source,
            args.output,
            character_map_file=args.character_map
        )
    else:
        # –†–µ–∂–∏–º –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –≤—Å–µ —Ñ–∞–π–ª—ã –∏–∑ extracted_scripts
        source_dir = "../extracted_scripts"
        output_dir = "../temp_files/llm_json_v2"
        character_map = "../data/characters.json"

        print("üöÄ –†–µ–∂–∏–º –ø–∞–∫–µ—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        print(f"üìÅ –í—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {source_dir}")
        print(f"üìÅ –í—ã—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {output_dir}")
        print(f"üìÅ –ö–∞—Ä—Ç–∞ –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π: {character_map}")
        print()

        preparer.prepare_batch(source_dir, output_dir, character_map_file=character_map)


if __name__ == "__main__":
    main()
